import streamlit as st
import joblib
import re
import nltk
import pandas as pd
import os
from bs4 import BeautifulSoup
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from deep_translator import GoogleTranslator
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split  # Th√™m d√≤ng n√†y ph√≤ng h·ªù logic chia t√°ch

# --- 1. C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Movie Sentiment AI", page_icon="üé¨")

# --- 2. T·∫¢I D·ªÆ LI·ªÜU NLTK & C·∫§U H√åNH STOPWORDS M·ªöI ---
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords', quiet=True)
try:
    nltk.data.find('corpora/wordnet')
except LookupError:
    nltk.download('wordnet', quiet=True)
try:
    nltk.data.find('corpora/omw-1.4')
except LookupError:
    nltk.download('omw-1.4', quiet=True)

lemmatizer = WordNetLemmatizer()

# --- C·∫¨P NH·∫¨T QUAN TR·ªåNG: Logic Stopwords kh·ªõp v·ªõi file Train ---
custom_stop_words = set(stopwords.words("english"))
negation_words = {"not", "no", "never", "nor", "n't"}
stop_words = {
                 lemmatizer.lemmatize(w)
                 for w in custom_stop_words
             } - negation_words  # Gi·ªØ l·∫°i c√°c t·ª´ ph·ªß ƒë·ªãnh


# --- 3. C√ÅC H√ÄM X·ª¨ L√ù (CORE FUNCTIONS) ---

# --- C·∫¨P NH·∫¨T QUAN TR·ªåNG: H√†m Clean Text kh·ªõp v·ªõi file Train ---
def clean_text(text):
    text = text.lower()  # Lower tr∆∞·ªõc
    text = BeautifulSoup(text, "html.parser").get_text()

    # Gi·ªØ l·∫°i d·∫•u nh√°y ƒë∆°n (') cho c√°c t·ª´ nh∆∞ don't, can't
    text = re.sub(r"[^a-z']", " ", text)
    text = re.sub(r"(.)\1{2,}", r"\1\1", text)
    text = re.sub(r"\s+", " ", text).strip()

    words = [
        lemmatizer.lemmatize(w)
        for w in text.split()
        if lemmatizer.lemmatize(w) not in stop_words
    ]
    return " ".join(words)


def translate_to_english(text):
    try:
        translator = GoogleTranslator(source='auto', target='en')
        return translator.translate(text)
    except Exception:
        return text


# H√†m l∆∞u Feedback
def save_feedback(text, correct_label):
    file_path = "feedback.csv"
    new_data = pd.DataFrame({'review': [text], 'sentiment': [correct_label]})

    if not os.path.exists(file_path):
        new_data.to_csv(file_path, index=False, mode='w')
    else:
        new_data.to_csv(file_path, index=False, mode='a', header=False)


# --- C·∫¨P NH·∫¨T QUAN TR·ªåNG: H√†m Retrain d√πng thu·∫≠t to√°n t·ªëi ∆∞u ---
def retrain_model():
    status_text = st.empty()
    status_text.info("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu g·ªëc v√† feedback m·ªõi...")

    # 1. ƒê·ªçc d·ªØ li·ªáu g·ªëc
    try:
        df_orig = pd.read_csv("imdb.csv")
    except FileNotFoundError:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y file imdb.csv g·ªëc!")
        return

    # 2. ƒê·ªçc d·ªØ li·ªáu feedback (n·∫øu c√≥)
    if os.path.exists("feedback.csv"):
        try:
            df_feed = pd.read_csv("feedback.csv")
            df_final = pd.concat([df_orig, df_feed], ignore_index=True)
            status_text.info(f"ƒê√£ t√¨m th·∫•y {len(df_feed)} m·∫´u feedback m·ªõi. ƒêang g·ªôp d·ªØ li·ªáu...")
        except pd.errors.EmptyDataError:
            df_final = df_orig
            status_text.warning("File feedback.csv b·ªã l·ªói ho·∫∑c r·ªóng. Ch·ªâ d√πng d·ªØ li·ªáu g·ªëc.")
    else:
        df_final = df_orig
        status_text.info("Ch∆∞a c√≥ feedback m·ªõi. Ch·ªâ train l·∫°i tr√™n d·ªØ li·ªáu g·ªëc.")

    # 3. X·ª≠ l√Ω d·ªØ li·ªáu
    status_text.info("‚è≥ ƒêang x·ª≠ l√Ω vƒÉn b·∫£n (Clean Text - Logic M·ªõi)...")
    df_final["review_clean"] = df_final["review"].apply(clean_text)

    le_new = LabelEncoder()
    y = le_new.fit_transform(df_final['sentiment'])

    status_text.info("‚è≥ ƒêang Vector h√≥a (TF-IDF N-gram)...")
    # C·∫•u h√¨nh TF-IDF chu·∫©n optimized
    tfidf_new = TfidfVectorizer(
        ngram_range=(1, 2),
        max_features=50000,
        min_df=3,
        max_df=0.9,
        sublinear_tf=True
    )
    X_tfidf = tfidf_new.fit_transform(df_final["review_clean"])

    status_text.info("‚è≥ ƒêang Train Model (Logistic Regression Tuned)...")
    # C·∫•u h√¨nh Model chu·∫©n optimized
    model_new = LogisticRegression(
        C=2.0,
        solver="liblinear",
        max_iter=2000,
        class_weight="balanced"
    )
    model_new.fit(X_tfidf, y)

    # 4. L∆∞u ƒë√® file c≈©
    joblib.dump(model_new, 'sentiment_model.pkl')
    joblib.dump(tfidf_new, 'tfidf_vectorizer.pkl')
    joblib.dump(le_new, 'label_encoder.pkl')

    status_text.success("‚úÖ ƒê√£ c·∫≠p nh·∫≠t Model th√†nh c√¥ng! H√£y t·∫£i l·∫°i trang (F5) ƒë·ªÉ √°p d·ª•ng.")
    st.cache_resource.clear()


# --- 4. LOAD MODEL ---
@st.cache_resource
def load_models():
    try:
        m = joblib.load('sentiment_model.pkl')
        v = joblib.load('tfidf_vectorizer.pkl')
        l = joblib.load('label_encoder.pkl')
        return m, v, l
    except FileNotFoundError:
        return None, None, None


model, tfidf, le = load_models()

# --- 5. GIAO DI·ªÜN (UI) ---
st.title("üé¨ M√¥ H√¨nh AI Ph√¢n T√≠ch C·∫£m X√∫c D·ª±a Tr√™n ƒê√°nh Gi√°")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Khu v·ª±c Admin")
    st.write("C·∫≠p nh·∫≠t ki·∫øn th·ª©c m·ªõi cho AI t·ª´ ph·∫£n h·ªìi.")
    if st.button("üöÄ Train l·∫°i Model ngay"):
        retrain_model()

    if os.path.exists("feedback.csv"):
        try:
            count = len(pd.read_csv("feedback.csv"))
            st.write(f"ƒêang c√≥ **{count}** m·∫´u feedback ch·ªù h·ªçc.")
        except:
            st.write("File feedback tr·ªëng.")
    else:
        st.write("Ch∆∞a c√≥ feedback n√†o.")

# Main UI
user_input = st.text_area("Nh·∫≠p b√¨nh lu·∫≠n phim (Vi·ªát/Anh):", height=100)
analyze_btn = st.button("üîç Ph√¢n T√≠ch")

# Session State
if 'prediction_result' not in st.session_state:
    st.session_state['prediction_result'] = None
if 'translated_text' not in st.session_state:
    st.session_state['translated_text'] = None
if 'show_fix_form' not in st.session_state:
    st.session_state['show_fix_form'] = False

if analyze_btn and user_input:
    if model is None:
        st.error("Ch∆∞a t√¨m th·∫•y model! H√£y ch·∫°y file train_final.py tr∆∞·ªõc ho·∫∑c b·∫•m n√∫t Train b√™n tr√°i.")
    else:
        with st.spinner('ƒêang suy nghƒ©...'):
            eng_text = translate_to_english(user_input)

            # QUAN TR·ªåNG: D√πng h√†m clean_text m·ªõi
            clean = clean_text(eng_text)

            vec = tfidf.transform([clean])
            pred_idx = model.predict(vec)[0]
            pred_label = le.inverse_transform([pred_idx])[0]
            proba = model.predict_proba(vec).max() * 100

            st.session_state['prediction_result'] = {'label': pred_label, 'proba': proba}
            st.session_state['translated_text'] = eng_text
            st.session_state['show_fix_form'] = False

# Hi·ªÉn th·ªã k·∫øt qu·∫£
if st.session_state['prediction_result']:
    res = st.session_state['prediction_result']
    eng_txt = st.session_state['translated_text']

    st.divider()
    if res['label'] == 'positive':  # Gi·∫£ s·ª≠ label encoded l√† 'positive'
        # Ki·ªÉm tra l·∫°i label g·ªëc trong dataset c·ªßa b·∫°n (0/1 hay pos/neg)
        # N·∫øu d√πng code c≈© c·ªßa b·∫°n th√¨ output l√† 'positive'/'negative' chu·ªói
        st.success(f"K·∫øt qu·∫£: **T√çCH C·ª∞C (KHEN)** (ƒê·ªô tin c·∫≠y: {res['proba']:.1f}%)")
    else:
        st.error(f"K·∫øt qu·∫£: **TI√äU C·ª∞C (CH√ä)** (ƒê·ªô tin c·∫≠y: {res['proba']:.1f}%)")

    if user_input != eng_txt:
        st.caption(f"D·ªãch sang Anh: {eng_txt}")
        st.caption(
            f"Cleaned Text (Debug): {clean_text(eng_txt)}")  # D√≤ng n√†y ƒë·ªÉ b·∫°n debug xem n√≥ c√≥ gi·ªØ l·∫°i ch·ªØ 'not' kh√¥ng

    st.write("---")
    st.write("**AI d·ª± ƒëo√°n c√≥ ƒë√∫ng kh√¥ng?**")

    c1, c2 = st.columns(2)
    with c1:
        if st.button("üëç ƒê√∫ng r·ªìi"):
            st.toast("C·∫£m ∆°n b·∫°n ƒë√£ x√°c nh·∫≠n!")
    with c2:
        if st.button("üëé Sai r·ªìi (S·ª≠a l·∫°i)"):
            st.session_state['show_fix_form'] = True

    if st.session_state['show_fix_form']:
        with st.form("fix_form"):
            st.write("H√£y d·∫°y l·∫°i AI: Theo b·∫°n, c√¢u n√†y th·ª±c ra l√† g√¨?")
            correct_val = st.radio("Nh√£n ƒë√∫ng l√†:", ["positive", "negative"])
            submit_fix = st.form_submit_button("G·ª≠i Feedback")

            if submit_fix:
                save_feedback(eng_txt, correct_val)
                st.success("‚úÖ ƒê√£ l∆∞u ph·∫£n h·ªìi! H√£y b·∫•m 'Train l·∫°i Model' b√™n menu tr√°i ƒë·ªÉ AI h·ªçc ngay.")
                st.session_state['show_fix_form'] = False
